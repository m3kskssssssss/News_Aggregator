import feedparser
import requests
from datetime import datetime


def fetch_rss_sources():
    """RSS –∏—Å—Ç–æ—á–Ω–∏–∫–∏ —Ä—É—Å—Å–∫–∏—Ö –Ω–æ–≤–æ—Å—Ç–µ–π"""
    # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –∑–¥–µ—Å—å —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å —Ü–∏–∫–ª–∏—á–µ—Å–∫–∏—Ö –∏–º–ø–æ—Ä—Ç–æ–≤
    from models import db, NewsSource, Article
    from summarizer import summarize_text

    rss_sources = [
        {
            'name': 'Lenta.ru',
            'url': 'https://lenta.ru/rss/news',
            'category': 'general'
        },
        {
            'name': 'RBC',
            'url': 'https://rssexport.rbc.ru/rbcnews/news/20/full.rss',
            'category': 'general'
        },
        {
            'name': 'Kommersant',
            'url': 'https://www.kommersant.ru/RSS/main.xml',
            'category': 'business'
        },
        {
            'name': 'Lenta.ru',
            'url': 'https://lenta.ru/rss/news',
            'category': 'general'
        },
        {
            'name': 'Gazeta.ru',
            'url': 'https://www.gazeta.ru/export/rss/lenta.xml',
            'category': 'general'
        },
        {
            'name': 'Vedomosti',
            'url': 'https://www.vedomosti.ru/rss/news',
            'category': 'business'
        },
        {
            'name': 'Sport Express',
            'url': 'https://www.sport-express.ru/services/materials/rss/',
            'category': 'sports'
        },
        {
            'name': 'Interfax',
            'url': 'https://www.interfax.ru/rss.asp',
            'category': 'general'
        }
    ]

    total_new = 0

    for rss_data in rss_sources:
        try:
            print(f"üîÑ –ó–∞–≥—Ä—É–∂–∞–µ–º RSS: {rss_data['name']} - {rss_data['url']}")

            # –ü–∞—Ä—Å–∏–º RSS —Å timeout
            feed = feedparser.parse(rss_data['url'])

            if not feed.entries:
                print(f"‚ùå RSS {rss_data['name']}: –Ω–µ—Ç —Å—Ç–∞—Ç–µ–π –≤ –ª–µ–Ω—Ç–µ")
                continue

            print(f"üìÑ RSS {rss_data['name']}: –Ω–∞–π–¥–µ–Ω–æ {len(feed.entries)} —Å—Ç–∞—Ç–µ–π –≤ –ª–µ–Ω—Ç–µ")

            # –°–æ–∑–¥–∞—Ç—å –∏—Å—Ç–æ—á–Ω–∏–∫ –µ—Å–ª–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
            source = NewsSource.query.filter_by(name=rss_data['name']).first()
            if not source:
                source = NewsSource(
                    name=rss_data['name'],
                    source_id=rss_data['name'].lower().replace('.', '_').replace(' ', '_'),
                    category=rss_data['category'],
                    language='ru',
                    country='ru',
                    is_active=True
                )
                db.session.add(source)
                db.session.commit()
                print(f"‚úÖ –°–æ–∑–¥–∞–Ω –Ω–æ–≤—ã–π –∏—Å—Ç–æ—á–Ω–∏–∫: {rss_data['name']}")

            # –ó–∞–≥—Ä—É–∑–∏—Ç—å —Å—Ç–∞—Ç—å–∏ –∏–∑ RSS
            new_articles = 0
            for i, entry in enumerate(feed.entries[:20]):  # –ü–µ—Ä–≤—ã–µ 20 —Å—Ç–∞—Ç–µ–π
                if not hasattr(entry, 'link') or not entry.link:
                    print(f"‚ö†Ô∏è  –°—Ç–∞—Ç—å—è {i + 1}: –Ω–µ—Ç —Å—Å—ã–ª–∫–∏")
                    continue

                existing = Article.query.filter_by(url=entry.link).first()
                if existing:
                    continue

                # –°–æ–∑–¥–∞–µ–º —Å–≤–æ–¥–∫—É
                title = getattr(entry, 'title', '–ë–µ–∑ –∑–∞–≥–æ–ª–æ–≤–∫–∞')
                description = getattr(entry, 'description', '')
                summary = ""

                if description:
                    try:
                        # –£–±–∏—Ä–∞–µ–º HTML —Ç–µ–≥–∏
                        import re
                        clean_desc = re.sub(r'<[^>]+>', '', description)
                        summary = summarize_text(clean_desc, sentences_count=1)
                    except Exception as e:
                        print(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏: {e}")
                        summary = description[:200] + "..." if len(description) > 200 else description

                # –ü–∞—Ä—Å–∏–º –¥–∞—Ç—É
                published_at = datetime.now()
                if hasattr(entry, 'published_parsed') and entry.published_parsed:
                    try:
                        published_at = datetime(*entry.published_parsed[:6])
                    except Exception as e:
                        print(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –¥–∞—Ç—ã: {e}")

                article = Article(
                    title=title,
                    description=description,
                    url=entry.link,
                    published_at=published_at,
                    source_id=source.id,
                    summary=summary
                )

                try:
                    db.session.add(article)
                    new_articles += 1
                    print(f"‚ûï –î–æ–±–∞–≤–ª–µ–Ω–∞ —Å—Ç–∞—Ç—å—è {new_articles}: {title[:50]}...")
                except Exception as e:
                    print(f"‚ùå –û—à–∏–±–∫–∞ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è —Å—Ç–∞—Ç—å–∏: {e}")

            if new_articles > 0:
                try:
                    db.session.commit()
                    print(f"‚úÖ RSS {rss_data['name']}: –¥–æ–±–∞–≤–ª–µ–Ω–æ {new_articles} –Ω–æ–≤—ã—Ö —Å—Ç–∞—Ç–µ–π")
                    total_new += new_articles
                except Exception as e:
                    print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤ –ë–î: {e}")
                    db.session.rollback()
            else:
                print(f"‚ÑπÔ∏è  RSS {rss_data['name']}: –Ω–æ–≤—ã—Ö —Å—Ç–∞—Ç–µ–π –Ω–µ—Ç (–≤—Å–µ —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É—é—Ç)")

        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ RSS {rss_data['name']}: {e}")
            db.session.rollback()

    print(f"üéâ –í—Å–µ–≥–æ –¥–æ–±–∞–≤–ª–µ–Ω–æ {total_new} –Ω–æ–≤—ã—Ö —Å—Ç–∞—Ç–µ–π –∏–∑ RSS")
    return total_new